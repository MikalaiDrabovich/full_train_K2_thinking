base_model_path: ./models/k2_domain_pretrain
output_dir: ./models/k2_domain_instruct
sft_data: ./data/domain_sft.jsonl
training:
  num_train_epochs: 2
  per_device_train_batch_size: 2
  gradient_accumulation_steps: 8
  learning_rate: 1.0e-05
  warmup_steps: 500
  weight_decay: 0.05
  logging_steps: 50
  save_steps: 1000
  bf16: true
  max_seq_length: 4096
